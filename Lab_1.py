# -*- coding: utf-8 -*-
"""prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v8vjlc55a9QILWS6JrhY3Z1efy2fPadu
"""

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
from numpy import asarray
import numpy as np
from matplotlib import pyplot
import math

data_age = [15,15,15,18,28,29,37,37,44,50,50,60,61,64,65,65,72,75,
            75,82,85,91,91,97,98,125,142,142,147,147,150,159,165,183,192,195,
            218,218,219,224,225,227,232,232,237,246,258,276,285,300,301,305,312,317,
            338,347,354,357,375,394,513,535,554,591,648,660,705,723,756,768,860]
data_weight = [21.66,22.75,22.3,31.25,44.79,40.55,
               50.25,46.88,52.03,63.47,61.13,81,73.09,
               79.09,79.51,65.31,71.9,86.1,94.6,92.5,
               105,101.7,102.9,110,104.3,134.9,130.68,
               140.58,155.3,152.2,144.5,142.15,139.81,
               153.22,145.72,161.1,174.18,173.03,
               173.54,178.86,177.68,173.73,159.98,161.29,
               187.07,176.13,183.4,186.26,189.66,186.09,
               186.7,186.8,195.1,216.41,203.23,188.38,189.7,
               195.31,202.63,224.82,203.3,209.7,233.9,234.7,
               244.3,231,242.4,230.77,242.57,232.12,246.7]

train_age = [] # тренировочный сет
train_weight = []
test_age = [] # тестовый сет(каждый 7 элемент)
test_weight = []

for i in range(0,len(data_age)):
  if ((i+1)%7==0):
    test_age.append(data_age[i])
    test_weight.append(data_weight[i])
  else:
    train_age.append(data_age[i])
    train_weight.append(data_weight[i])



# define the dataset
x = asarray(train_age)
y = asarray(train_weight)


x_test = asarray(test_age)
y_test = asarray(test_weight)
print(x.min(), x.max(), y.min(), y.max())
print(len(x))
print(len(y))

# reshape arrays into into rows and cols
x = x.reshape((len(x), 1))
y = y.reshape((len(y), 1))
# separately scale the input and output variables
scale_x = MinMaxScaler()
x = scale_x.fit_transform(x)
scale_y = MinMaxScaler()
y = scale_y.fit_transform(y)
print(x.min(), x.max(), y.min(), y.max())

# design the neural network model
model = Sequential()
model.add(Dense(10, input_dim=1, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(10, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(1))

# define the loss function and optimization algorithm
model.compile(loss='mse', optimizer='adam')
# ft the model on the training dataset
model.fit(x, y, epochs=500, batch_size=10, verbose=0)
# make predictions for the input data
x_test = x_test.reshape((len(x_test), 1))
yhat = model.predict(scale_x.fit_transform(x_test))
# inverse transforms
x_plot = scale_x.inverse_transform(x)
y_plot = scale_y.inverse_transform(y)
yhat_plot = scale_y.inverse_transform(yhat)
# report model error
print('MSE: %.3f' % mean_squared_error(y_test, yhat_plot))
print(yhat_plot)
print(y_test)

x_func = np.linspace(0,800,80)
y_func = []
for i in range(0,len(data_age)):
  y_func.append(233.846*(1-np.exp(-0.006042*x_func[i])))

# plot x vs y
pyplot.scatter(x_plot,y_plot, label='Actual')
# plot x vs yhat
pyplot.scatter(x_test,yhat_plot, label='Predicted')
pyplot.plot(data_age,y_func, label='Function')
pyplot.title('Input (x) versus Output (y)')
pyplot.xlabel('Input Variable (x)')
pyplot.ylabel('Output Variable (y)')
pyplot.legend()
pyplot.show()

from keras.utils import plot_model
plot_model(model, to_file='model.png')

for layer in model.layers:
    weights = layer.get_weights() # list of numpy arrays
    print(weights)



